# Banking Customer Query Analytics Pipeline

## ğŸ“Œ Project Description
This project demonstrates an **end-to-end ETL pipeline** using **Azure Data Factory (ADF)** to load banking customer queries from CSV files into **Azure SQL Database** for analytics.

The pipeline was tested successfully with **8 rows copied** from a sample CSV into SQL.

---

## ğŸ¯ Objective
- Automate loading of banking customer queries from raw CSV files  
- Learn and showcase Azure Data Factory pipeline design  
- Validate data ingestion into Azure SQL Database  
- Document and publish project for GitHub portfolio  

---

## ğŸ—ï¸ Architecture Diagram
![Pipeline Architecture](Diagrams/pipeline_architecture.png)

---

## âš™ï¸ Tech Stack
- **Azure Data Factory** â€“ ETL pipeline orchestration  
- **Azure Storage Account** â€“ CSV source files  
- **Azure SQL Database** â€“ sink table for customer queries  
- **Integration Runtime** â€“ AutoResolveIntegrationRuntime  

---

## ğŸ”„ Pipeline Workflow
1. **Source**: Customer queries stored in Azure Blob Storage (CSV).  
2. **ADF Pipeline**: Copy Activity moves data from Storage â†’ SQL.  
3. **Sink**: Data stored in `dbo.CustomerQueries` table.  
4. **Execution**: Pipeline triggered manually for testing.  
5. **Monitoring**: Run validated in ADF Monitor tab.  

---

## ğŸ“‚ Folder Structure
ADF_Pipeline_Project/
â”‚
â”œâ”€â”€ README.md # Project documentation
â”œâ”€â”€ ADF_Pipelines/ # Exported pipeline JSON
â”‚ â””â”€â”€ pipeline.json
â”œâ”€â”€ Sample_Data/ # Input CSV data
â”‚ â””â”€â”€ customer_queries.csv
â”œâ”€â”€ Screenshots/ # Screenshots of pipeline and results
â”‚ â”œâ”€â”€ pipeline_design.png
â”‚ â”œâ”€â”€ debug_run.png
â”‚ â”œâ”€â”€ monitor_tab.png
â”‚ â””â”€â”€ sql_table.png
â””â”€â”€ Diagrams/ # Architecture diagram
â””â”€â”€ architecture.png

---

## âš™ï¸ Pipeline Steps
1. **Create Linked Services**  
   - Azure Blob Storage (source)  
   - Azure SQL Database (sink)  

2. **Create Datasets**  
   - Source dataset â†’ `customer_queries.csv`  
   - Sink dataset â†’ SQL table `CustomerQueries`  

3. **Build Pipeline**  
   - Copy Activity: Blob â†’ SQL  

4. **Run & Monitor**  
   - Debug â†’ verify row copy  
   - Trigger Now â†’ run pipeline  
   - Monitor â†’ confirm success  

---

## ğŸ“Š Sample Data
Sample banking customer query data was used in CSV format.  
Example columns:  
- QUERY_ID  
- CUSTOMER_ID  
- QUERY_TEXT  
- DATE  
- CHANNEL  

---

## ğŸ–¼ï¸ Screenshots

### ğŸ”¹ Pipeline Design
![Pipeline Design](Screenshots/pipeline_design.png)

### ğŸ”¹ Debug Run (Rows Copied = 8)
![Debug Run](Screenshots/debug_run.png)

### ğŸ”¹ Monitor Tab (Successful Pipeline Run)
![Monitor Tab](Screenshots/monitor_tab.png)

### ğŸ”¹ SQL Table with Data
![SQL Table](Screenshots/sql_table.png)

---

## ğŸ§‘â€ğŸ’» Skills Demonstrated
- **ETL pipeline design** in Azure Data Factory  
- Creation of **linked services, datasets, and sink tables**  
- Running pipelines with **debug and trigger now**  
- **Monitoring** pipeline runs and validating data load  
- Documenting project and publishing on **GitHub**  

---

## âœ… Outcome
- 8 rows successfully ingested from **CSV â†’ Azure SQL Database**  
- Fully documented project with pipeline JSON, sample data, and screenshots  
- Ready-to-showcase portfolio project for **Azure Data Engineer** roles  
